#### LSTM
	
	# data shape = (samples, time_steps, features)

		# applies to both X and y
		# samples    = number of observations
		# time_steps = number of elements in a sequence
		# features   = either the number of unique features such as pressure and temperature
		#              OR
		#              the size of vocabulary in case of one-hot-encoded vector of elements or word embeddings
		#              OR
		#              multi-dimensional in case of CNN-LSTM architecture --> (samples, time_steps, height, width, channels)

	### Vanilla LSTM
	model = Sequential()
	model.add(LSTM(10, input_shape=(10, 25)))  # input shape = (time_steps, features)
	model.add(Dense(1))

	# stateful LSTM -- when order of training example is also important
	model.add(LSTM(2, stateful=True, batch_input_shape=(32, 10, 25)))
	epochs = 1000
	for i in range(epochs):
		model.fit(X, y, epochs=1, shuffle=False, batch_input_shape=(32, 10, 25))
		model.reset_states()
	predictions = model.predict(X, batch_size=32)
	
	#### Types of LSTM architectures

		# one-to-one LSTM - equivalent of vanilla neural network
		model = Sequential()
		model.add(LSTM(..., input_shape=(1, features)))           # single input
		model.add(Dense(1))                                       # single output

		# many-to-one LSTM
		model = Sequential()
		model.add(LSTM(..., input_shape=(time_steps, features)))  # multiple inputs (one at each timestep)
		model.add(Dense(1))                                       # single output (at the end of sequence)

		# one-to-many LSTM
		model = Sequential()
		model.add(Conv2D(...))                                    # single input at the first timestep: single encoded image (output of a CNN)
		...
		model.add(LSTM(..., return_sequences=True))               # make sure return_sequences=True for multiple outputs
		model.add(TimeDistributed(Dense(1)))                      # multiple outputs (one at each timestep)

		
		# many-to-many LSTM (len(input) == len(output))
		model = Sequential()
		model.add(LSTM(..., input_shape=(time_steps, features),   # multiple inputs (one at each timestep)
					   return_sequences=True))                    # make sure return_sequences=True for multiple outputs
		model.add(TimeDistributed(Dense(1)))                      # multiple outputs (one at each timestep)

		# many-to-many LSTM (len(input) != len(output)) encoder-decoder architecture
		model = Sequential()
		model.add(LSTM(..., input_shape=(in_steps, ...)))            # multiple inputs (one at each timestep of the encoder)
		model.add(RepeatVector(out_steps))                           # output of encoder at last timestep is fed to first timestep of decoder
		model.add(LSTM(..., return_sequences=True))                  # make sure return_sequences=True for multiple outputs
		model.add(TimeDistributed(Dense(1, activation='sigmoid')))   # multiple outputs (one at each timestep of the decoder)

	# Vanilla LSTM
	
		model = Sequential()
		model.add(LSTM(..., input_shape=(time_steps, features)))
		model.add(Dense(...))

	# Stacked LSTM
		
		model = Sequential()
		model.add(LSTM(..., return_sequences=True, input_shape=(...)))
		model.add(LSTM(..., return_sequences=True))
		model.add(LSTM(..., return_sequences=True))  # return sequences returns 3D output to next layer instead of 2D
		model.add(LSTM(...))
		model.add(Dense(...))
		
	# CNN-LSTM

		# apply cnn --> then lstm
		# cnn (extracts spatial structure) is used to extract features from images - 
		# lstm (extracts temporal structure of a sequence) is applied to, say, a series of images
		# cnn is applied to each time-step and hence we should use TimeDistributed()
		# TimeDistributed() makes it compatible with lstm (that is, cnn outputs what lstm expects)
		
		# data shape --> [samples, timesteps, width, height, channels]

		model = Sequential()
		
		# define CNN model
		# cnn should be applied to each time step, hence use TimeDistributed()
		model.add(TimeDistributed(Conv2D(...))
		model.add(TimeDistributed(MaxPooling2D(...)))
		model.add(TimeDistributed(Flatten()))
		
		# define LSTM model
		model.add(LSTM(...))
		model.add(Dense(...))

	# encoder-decoder

		

	# bidirectional LSTM

		model.add(Bidirectional(LSTM(...), input_shape=(...), merge_mode='concat'))
